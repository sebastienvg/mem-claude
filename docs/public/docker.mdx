---
title: Docker Installation
description: Run claude-mem using Docker
---

# Docker Installation

Run claude-mem in a container for easy deployment and isolation.

<Warning>
**Host Requirement:** Even when running the worker in Docker, you must have **bun** installed on your host machine. The Claude Code plugin hooks run locally and require bun to function.

```bash
# Install bun on the host
curl -fsSL https://bun.sh/install | bash
```
</Warning>

## Quick Start

```bash
# Pull the latest image
docker pull registry.evthings.space/mem-claude/claude-mem:latest

# Run with Ollama (fully local, no API costs - recommended)
docker run -d \
  --name claude-mem \
  -p 37777:37777 \
  -v ~/.claude-mem:/data \
  -e CLAUDE_MEM_PROVIDER=ollama \
  -e CLAUDE_MEM_OLLAMA_URL=http://host.docker.internal:11434 \
  registry.evthings.space/mem-claude/claude-mem:latest

# Or run with OpenRouter (has free models)
docker run -d \
  --name claude-mem \
  -p 37777:37777 \
  -v ~/.claude-mem:/data \
  -e CLAUDE_MEM_PROVIDER=openrouter \
  -e CLAUDE_MEM_OPENROUTER_API_KEY=$OPENROUTER_API_KEY \
  registry.evthings.space/mem-claude/claude-mem:latest
```

## Docker Compose (Recommended)

For the full stack including vector search:

```bash
# Clone the repository
git clone https://github.com/thedotmack/claude-mem.git
cd claude-mem

# Configure environment
cp .env.example .env
# Edit .env with your API key

# Start services
docker compose up -d
```

## Environment Variables

The worker service uses an AI model to compress and summarize your observations. Choose one provider:

| Variable | Description |
|----------|-------------|
| `CLAUDE_MEM_PROVIDER` | Provider: `ollama`, `openrouter`, `gemini`, or `claude` |
| `CLAUDE_MEM_OLLAMA_URL` | Ollama endpoint (default: `http://localhost:11434`) |
| `CLAUDE_MEM_OLLAMA_MODEL` | Ollama model (default: `llama3.2`) |
| `CLAUDE_MEM_OPENROUTER_API_KEY` | OpenRouter API key |
| `CLAUDE_MEM_GEMINI_API_KEY` | Gemini API key |
| `ANTHROPIC_API_KEY` | Claude API key |

**Recommended:** Use **Ollama** for fully local operation with no API costs.

## Using Ollama (Recommended)

For self-hosted operation with no API costs:

### With existing Ollama instance:
```bash
-e CLAUDE_MEM_PROVIDER=ollama \
-e CLAUDE_MEM_OLLAMA_URL=http://host.docker.internal:11434
```

### Run Ollama in Docker:
Uncomment the `ollama` service in `docker-compose.yml`, then:
```bash
docker compose up -d
docker exec claude-mem-ollama ollama pull llama3.2
```

### Recommended models:
- `llama3.2` - Fast, good quality (default)
- `mistral` - Excellent for structured extraction
- `phi3` - Smaller, faster

## Data Persistence

Mount `/data` to persist:
- SQLite database
- Vector embeddings
- Session logs
- Configuration

```bash
-v ~/.claude-mem:/data
```

## Health Check

```bash
curl http://localhost:37777/api/readiness
```

## Updating

```bash
docker pull registry.evthings.space/mem-claude/claude-mem:latest
docker compose up -d
```

## Troubleshooting

### Container won't start
Check logs: `docker logs claude-mem`

### Permission denied on /data
Ensure mount directory exists and is writable:
```bash
mkdir -p ~/.claude-mem
chmod 755 ~/.claude-mem
```

### Can't connect to worker
Verify port is exposed: `docker ps`
Check firewall allows 37777

---

## Integrating with Claude Code

The containerized worker provides the HTTP API. To use with Claude Code:

### Option 1: Plugin + Remote Worker (Recommended)

Install the plugin, then point it to your container:

```bash
# In Claude Code:
> /plugin marketplace add thedotmack/claude-mem
> /plugin install claude-mem
```

Set worker URL in `~/.claude-mem/settings.json`:
```json
{
  "CLAUDE_MEM_WORKER_URL": "http://localhost:37777"
}
```

### Option 2: MCP Server Only

Configure Claude Code's MCP settings (`~/.claude/settings.json`):

```json
{
  "mcpServers": {
    "claude-mem": {
      "type": "stdio",
      "command": "node",
      "args": ["/path/to/mcp-server.cjs"],
      "env": {
        "CLAUDE_MEM_WORKER_URL": "http://localhost:37777"
      }
    }
  }
}
```

### Web Viewer UI

Access the memory viewer at: **http://localhost:37777**

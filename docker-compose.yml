services:
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: claude-mem-worker
    ports:
      - "${CLAUDE_MEM_WORKER_PORT:-37777}:37777"
    volumes:
      - claude-mem-data:/data
    environment:
      - CLAUDE_MEM_DATA_DIR=/data
      - CLAUDE_MEM_WORKER_HOST=0.0.0.0
      - CLAUDE_MEM_WORKER_PORT=37777
      - CLAUDE_MEM_CHROMA_MODE=http
      - CLAUDE_MEM_CHROMA_URL=http://chroma:8000
      - CLAUDE_MEM_MODEL=${CLAUDE_MEM_MODEL:-claude-sonnet-4-5}
      - CLAUDE_MEM_PROVIDER=${CLAUDE_MEM_PROVIDER:-claude}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - CLAUDE_MEM_GEMINI_API_KEY=${CLAUDE_MEM_GEMINI_API_KEY:-}
      - CLAUDE_MEM_OPENROUTER_API_KEY=${CLAUDE_MEM_OPENROUTER_API_KEY:-}
      - CLAUDE_MEM_OLLAMA_URL=${CLAUDE_MEM_OLLAMA_URL:-http://ollama:11434}
      - CLAUDE_MEM_OLLAMA_MODEL=${CLAUDE_MEM_OLLAMA_MODEL:-llama3.2}
    depends_on:
      chroma:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:37777/api/readiness"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  chroma:
    image: chromadb/chroma:latest
    container_name: claude-mem-chroma
    volumes:
      - chroma-data:/chroma/chroma
    environment:
      - ANONYMIZED_TELEMETRY=False
      - CHROMA_SERVER_AUTHN_PROVIDER=
      - CHROMA_SERVER_AUTHN_CREDENTIALS=
    # Note: Chroma image has minimal tooling, skip health check
    # Worker will retry connection if Chroma isn't ready
    restart: unless-stopped

  # Optional: Local Ollama for self-hosted AI (no API costs)
  # Uncomment to use Ollama instead of cloud providers
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: claude-mem-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 5
  #     start_period: 30s
  #   restart: unless-stopped
  #   # Pull a model on first run: docker exec claude-mem-ollama ollama pull llama3.2

volumes:
  claude-mem-data:
    name: claude-mem-data
  chroma-data:
    name: claude-mem-chroma-data
  # ollama-data:
  #   name: claude-mem-ollama-data

networks:
  default:
    name: claude-mem-network
